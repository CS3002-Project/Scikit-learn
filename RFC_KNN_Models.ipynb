{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import time\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does dataframe contain NaN values? False\n"
     ]
    }
   ],
   "source": [
    "##Preprocessing\n",
    "\n",
    "##Using dataset with ideal placement of sensors.\n",
    "data = pd.read_csv(\"subject4_ideal.log\",delim_whitespace=True,header=None)\n",
    "#print(data)\n",
    "\n",
    "##Check if dataframe contains NaN values, returns true if there are.\n",
    "print(\"Does dataframe contain NaN values? {}\".format(data.isnull().any().any()))\n",
    "\n",
    "##Remove previous preprocessed file\n",
    "if (os.path.exists('np.txt') == True):\n",
    "    os.remove(\"np.txt\")\n",
    "\n",
    "##Feature selection with MEAN to reduce file size/rows. \n",
    "i = 0\n",
    "rows_per_partition = 10\n",
    "start = 0\n",
    "end = rows_per_partition\n",
    "remainder_rows = data.shape[0]%rows_per_partition\n",
    "f = open(\"np.txt\", \"a\")\n",
    "while (i<data.shape[0]):\n",
    "    \n",
    "    np.savetxt(f, data[start:end].mean(axis=0).to_frame().T, fmt='%.6f', delimiter=' ')\n",
    "    i+=rows_per_partition\n",
    "    start += rows_per_partition\n",
    "    end += rows_per_partition\n",
    "\n",
    "##Add remainder rows\n",
    "#print(data[data.shape[0] - remainder_rows :data.shape[0]])\n",
    "np.savetxt(f, data[data.shape[0] - remainder_rows :data.shape[0]].mean(axis=0).to_frame().T, fmt='%.6f', delimiter=' ')\n",
    "\n",
    "\n",
    "##Standardize/Normalize features (Mean = 0, S.D = 1) \n",
    "def standardise_dataset(X_train, X_test):\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "##Dropping QUAT and MAG columns as they are not relevant to the context of our project\n",
    "delete_columns = []\n",
    "count = 0;\n",
    "i = 2;\n",
    "while i < len(data.columns):\n",
    "    count += 1\n",
    "    if(count==6):\n",
    "        #print(i)\n",
    "        for j in range(8):\n",
    "            delete_columns.append(i)\n",
    "            i += 1\n",
    "        count = 0\n",
    "        i -=1\n",
    "    i += 1\n",
    "\n",
    "##Use preprocessed txt file\n",
    "data = pd.read_csv(\"np.txt\",delim_whitespace=True,header=None)\n",
    "#print(data)\n",
    "\n",
    "X = data.drop(delete_columns, axis = 1)        \n",
    "Y = data[119].round().astype(int)\n",
    "\n",
    "#print(data[119].unique())\n",
    "#print(Y.unique())\n",
    "\n",
    "##Splitting dataset into 80% training data and 20% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "#print(y_train, y_test)\n",
    "##Standardize features\n",
    "X_train, X_test = standardise_dataset(X_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evluation for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Train Accuracy: 0.9671274443695212\n",
      "Test Accuracy: 0.9582210242587601\n",
      "Predicted    0   1   2   3   4   5   6   7  8   9  ...  23  24  25  26  27  \\\n",
      "True                                               ...                       \n",
      "0          760  13   4   7   1   0   0   2  0   0  ...   0   0   1   0   0   \n",
      "1            2  48   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "2            4   1  65   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "3            0   0   0  40   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "4            0   0   0   0  12   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "5            0   0   0   0   4  19   0   0  0   0  ...   0   0   0   0   0   \n",
      "6            0   0   0   0   1   0  20   0  0   0  ...   0   0   0   0   0   \n",
      "7            0   0   0   0   1   0   0  15  0   0  ...   0   0   0   0   0   \n",
      "8            0   0   0   0   0   0   0   0  9   0  ...   0   0   0   0   0   \n",
      "9            1   0   0   0   0   0   0   0  0  25  ...   0   0   0   0   0   \n",
      "10           1   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "11           1   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "12           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "13           1   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "14           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "15           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "16           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "17           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "18           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "20           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "21           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "22           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "23           0   0   0   0   0   0   0   0  0   0  ...  19   0   0   0   0   \n",
      "24           0   0   0   0   0   0   0   0  0   0  ...   0  10   0   0   0   \n",
      "25           0   0   0   0   0   0   0   0  0   0  ...   0   0  15   0   0   \n",
      "26           0   1   0   0   0   0   0   0  0   0  ...   0   0   0   7   0   \n",
      "27           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0  10   \n",
      "28           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "29           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "30           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "31           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "All        770  63  69  47  19  19  20  17  9  25  ...  19  10  16   7  10   \n",
      "\n",
      "Predicted  28  29  30  31   All  \n",
      "True                             \n",
      "0           1   0   1   0   799  \n",
      "1           0   0   0   0    50  \n",
      "2           0   0   0   0    70  \n",
      "3           0   0   0   0    40  \n",
      "4           0   0   0   0    13  \n",
      "5           0   0   0   0    23  \n",
      "6           0   0   0   0    22  \n",
      "7           0   0   0   0    16  \n",
      "8           0   0   0   0     9  \n",
      "9           0   0   0   0    26  \n",
      "10          0   0   0   0    23  \n",
      "11          0   0   0   0    30  \n",
      "12          0   0   0   0    17  \n",
      "13          0   0   0   0    35  \n",
      "14          0   0   0   0    25  \n",
      "15          0   0   0   0    25  \n",
      "16          0   0   0   0    18  \n",
      "17          0   0   0   0     4  \n",
      "18          0   0   1   0     1  \n",
      "20          0   0   0   0    23  \n",
      "21          0   0   0   0    17  \n",
      "22          0   0   0   0    16  \n",
      "23          0   0   0   0    19  \n",
      "24          0   0   0   0    10  \n",
      "25          0   0   0   0    15  \n",
      "26          0   0   0   0     8  \n",
      "27          0   0   0   0    10  \n",
      "28         33   0   0   0    33  \n",
      "29          0  34   0   0    34  \n",
      "30          0   0  19   0    19  \n",
      "31          0   0   0  34    34  \n",
      "All        34  34  21  34  1484  \n",
      "\n",
      "[32 rows x 31 columns]\n",
      "--- 4.091127634048462 seconds ---\n",
      "\n",
      "Evluation for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.9919137466307277\n",
      "Predicted    0   1   2   3   4   5   6   7  8   9  ...  23  24  25  26  27  \\\n",
      "True                                               ...                       \n",
      "0          798   0   0   0   0   0   0   1  0   0  ...   0   0   0   0   0   \n",
      "1            0  49   1   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "2            0   0  70   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "3            0   0   0  40   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "4            1   0   0   0  11   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "5            0   0   0   0   0  23   0   0  0   0  ...   0   0   0   0   0   \n",
      "6            0   0   0   0   0   0  21   0  0   0  ...   0   0   0   0   0   \n",
      "7            0   0   0   0   0   0   0  16  0   0  ...   0   0   0   0   0   \n",
      "8            0   0   0   0   0   0   0   0  9   0  ...   0   0   0   0   0   \n",
      "9            0   0   0   0   0   0   0   0  0  26  ...   0   0   0   0   0   \n",
      "10           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "11           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "12           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "13           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "14           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "15           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "16           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "17           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "18           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "20           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "21           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "22           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "23           0   0   0   0   0   0   0   0  0   0  ...  19   0   0   0   0   \n",
      "24           0   0   0   0   0   0   0   0  0   0  ...   0  10   0   0   0   \n",
      "25           0   0   0   0   0   0   0   0  0   0  ...   0   0  15   0   0   \n",
      "26           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   7   0   \n",
      "27           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0  10   \n",
      "28           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "29           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "30           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "31           0   0   0   0   0   0   0   0  0   0  ...   0   0   0   0   0   \n",
      "All        799  49  71  40  11  23  21  17  9  26  ...  19  10  15   7  10   \n",
      "\n",
      "Predicted  28  29  30  31   All  \n",
      "True                             \n",
      "0           0   0   0   0   799  \n",
      "1           0   0   0   0    50  \n",
      "2           0   0   0   0    70  \n",
      "3           0   0   0   0    40  \n",
      "4           0   0   0   0    13  \n",
      "5           0   0   0   0    23  \n",
      "6           0   0   0   0    22  \n",
      "7           0   0   0   0    16  \n",
      "8           0   0   0   0     9  \n",
      "9           0   0   0   0    26  \n",
      "10          0   0   0   0    23  \n",
      "11          0   0   0   0    30  \n",
      "12          0   0   0   0    17  \n",
      "13          0   0   0   0    35  \n",
      "14          0   0   0   0    25  \n",
      "15          0   0   0   0    25  \n",
      "16          0   0   0   0    18  \n",
      "17          0   0   0   0     4  \n",
      "18          0   0   1   0     1  \n",
      "20          0   0   0   0    23  \n",
      "21          0   0   0   0    17  \n",
      "22          0   0   0   0    16  \n",
      "23          0   0   0   0    19  \n",
      "24          0   0   0   0    10  \n",
      "25          0   0   0   0    15  \n",
      "26          0   1   0   0     8  \n",
      "27          0   0   0   0    10  \n",
      "28         33   0   0   0    33  \n",
      "29          0  34   0   0    34  \n",
      "30          0   0  19   0    19  \n",
      "31          0   0   0  34    34  \n",
      "All        33  35  20  34  1484  \n",
      "\n",
      "[32 rows x 31 columns]\n",
      "--- 0.8447425365447998 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, X_train, y_train):\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def eval_model(clf, X_test, y_test, X_train, y_train):\n",
    "    pred_clf = clf.predict(X_test)\n",
    "    acc_test = clf.score(X_test, y_test)\n",
    "    acc_train = clf.score(X_train, y_train)\n",
    "    \n",
    "    print(\"Evluation for {}\".format(clf))\n",
    "    print(\"Train Accuracy: {}\".format(acc_train))    \n",
    "    print(\"Test Accuracy: {}\".format(acc_test))\n",
    "    #print(classification_report(y_test, pred_clf))\n",
    "    #print(confusion_matrix(y_test, pred_clf))\n",
    "    print(pd.crosstab(y_test, pred_clf, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "knn_clf = train_model(KNeighborsClassifier(), X_train, y_train)\n",
    "eval_model(knn_clf, X_test, y_test, X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "rf_clf = train_model(RandomForestClassifier(n_estimators = 20), X_train, y_train)\n",
    "eval_model(rf_clf, X_test, y_test, X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"\")\n",
    "\n",
    "# param_grid = { \n",
    "#     'n_estimators': [200, 700],\n",
    "# }\n",
    "# rfc = RandomForestClassifier(n_estimators=50) \n",
    "# CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid)\n",
    "# CV_rfc.fit(X_train, y_train)\n",
    "# print (CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
